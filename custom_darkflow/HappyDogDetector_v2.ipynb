{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation from online for custom YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_images_download import google_images_download\n",
    "import os\n",
    "original_path = os.getcwd()\n",
    "data_path = os.path.join(os.path.dirname(original_path),'downloads')\n",
    "response = google_images_download.googleimagesdownload()\n",
    "search_queries = ['picture with dogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadimages(query):\n",
    "    arguments = dict(keywords=query,\n",
    "                    limit=1000,\n",
    "                    format='jpg',\n",
    "                    output_directory=data_path,\n",
    "                    chromedriver='C:\\\\Users\\\\sungsooc\\\\Documents\\\\chromedriver_win32\\\\chromedriver.exe', \n",
    "                    silent_mode=True)   \n",
    "    response.download(arguments)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images for: picture with dogs ...\n",
      "Getting you a lot of images. This may take a few moments...\n",
      "Reached end of Page.\n",
      "\n",
      "\n",
      "Unfortunately all 1000 could not be downloaded because some images were not downloadable. 807 is all we got for this search filter!\n",
      "Downloaded 807 picture with dogs images!\n"
     ]
    }
   ],
   "source": [
    "download_msg = []\n",
    "for query in search_queries: \n",
    "    downloadimages(query)\n",
    "    msg = 'Downloaded {} {} images!'.format(len(os.listdir(os.path.join(data_path,query))),query)\n",
    "    download_msg.append(msg)\n",
    "for msg in download_msg:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.path.join(data_path,'picture with dogs')\n",
    "os.chdir(working_dir)\n",
    "current_list = os.listdir(os.getcwd())\n",
    "for i in range(len(os.listdir(working_dir))):\n",
    "    original_name = current_list[i]\n",
    "    new_name = \"\".join('picture with dogs'.split()) + '_{:04d}'.format(i+1) + os.path.splitext(original_name)[-1]\n",
    "    if not os.path.exists(new_name):\n",
    "        os.rename(original_name,new_name)\n",
    "os.chdir(original_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labelimg_v1.8.0 ([source](https://github.com/tzutalin/labelImg))\n",
    "<p align=\"center\">\n",
    "<img src=\"../Readme_images/hdd_v2_labelling_example.png\" width=\"700\"></p>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import pafy\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config custom darkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(config=config) as sess:\n",
    "    options = {\n",
    "        'model':os.path.join('cfg','yolov2_hddv2.cfg'), ## for custom model\n",
    "        'load':os.path.join('bin','yolov2.weights'),\n",
    "        'epoch':2,\n",
    "        'batch':1,\n",
    "        'train':True,\n",
    "        'dataset':os.path.join('..','downloads','picture with dogs'),\n",
    "        'annotation':os.path.join('..','downloads','picture with dogs-annot'),\n",
    "        'gpu':0.8\n",
    "    }\n",
    "    tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tfnet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    options = {\n",
    "        'model':os.path.join('cfg','yolov2_hddv2.cfg'), ## for custom model\n",
    "        'load':-1,\n",
    "        'gpu':1.0,\n",
    "        'threshold':0.3\n",
    "    }\n",
    "    tfnet2 = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfnet2.load_from_ckpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_images/3.jpg')\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "results = tfnet2.return_predict(img)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(img,prediction):\n",
    "    newimg = np.copy(img)\n",
    "    for r in prediction:\n",
    "        tl = (r['topleft']['x'], r['topleft']['y'])\n",
    "        br = (r['bottomright']['x'], r['bottomright']['y'])\n",
    "        label = r['label']\n",
    "        if label == 'dog':\n",
    "            newimg = cv2.rectangle(img,tl,br,(255,0,0),thickness=4)\n",
    "        if label == 'dogff':\n",
    "            newimg = cv2.rectangle(img,tl,br,(0,0,255),thickness=4)\n",
    "            \n",
    "#         conf = r['confidence'] # confidence of general dog detector\n",
    "#         text = '{}({:.2f})'.format(label,conf)\n",
    "#         text = '{}({:.3f})'.format(predict_class,predict_rate)\n",
    "#         img = cv2.rectangle(img, box_coords[0], box_coords[1], box_color, cv2.FILLED)\n",
    "#         newimg = cv2.rectangle(img,tl,br,(255,0,0),thickness=4)\n",
    "#         img = cv2.putText(img,text,tl,cv2.FONT_HERSHEY_PLAIN,2,txt_color,3)\n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.imshow(plot_box(img,results))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import hdc_v2 and co-register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = 'best-wiehgts-Model_2_2-057-0.314-0.870.hdf5'\n",
    "chosen_model = load_model(os.path.join('best_models_hdc_v2',model_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyPrediction(img):\n",
    "    crop_img = img[result[0]['topleft']['y']:result[0]['bottomright']['y'],result[0]['topleft']['x']:result[0]['bottomright']['x']]\n",
    "    img_rows = 224\n",
    "    img_cols = 224\n",
    "    crop_img = cv2.resize(crop_img,(img_rows,img_cols)).astype('float32')\n",
    "    crop_img /= 255\n",
    "    crop_img = np.expand_dims(crop_img,axis=0)\n",
    "    predict_rate = chosen_model.predict(crop_img)[0][0]\n",
    "    if predict_rate >= 0.5:\n",
    "        predict_class = 'happy'\n",
    "    else: predict_class = 'sad'\n",
    "    return predict_class,predict_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_box_color = (255,0,0)\n",
    "sad_box_color = (0,0,255)\n",
    "txt_color = (255,255,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2,figsize=(8*2, 6*3))\n",
    "for ax,img_num in zip(axes.flatten(),range(1,7)):\n",
    "    img = cv2.imread(os.path.join('custom_darkflow','test_images',str(img_num)+'.jpg'))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    result = tfnet.return_predict(img)\n",
    "    for r in result:\n",
    "        tl = (r['topleft']['x'], r['topleft']['y'])\n",
    "        br = (r['bottomright']['x'], r['bottomright']['y'])\n",
    "        label = r['label']\n",
    "        if label == 'dog':     \n",
    "#             conf = r['confidence'] # confidence of general dog detector\n",
    "#             text = '{}({:.2f})'.format(label,conf)\n",
    "            predict_class,predict_rate = HappyPrediction(img) # confidence of happy dog classifier\n",
    "            text = '{}({:.3f})'.format(predict_class,predict_rate)\n",
    "            (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN,2,5)[0]\n",
    "            text_offset_x = tl[0]-3\n",
    "            text_offset_y = tl[1]\n",
    "            box_coords = ((text_offset_x, text_offset_y+10), (text_offset_x+text_width,text_offset_y-text_height-10))\n",
    "            if predict_class == 'happy':\n",
    "                box_color = happy_box_color\n",
    "            else:\n",
    "                box_color = sad_box_color\n",
    "            img = cv2.rectangle(img, box_coords[0], box_coords[1], box_color, cv2.FILLED)\n",
    "            img = cv2.rectangle(img,tl,br,box_color,thickness=4)\n",
    "            img = cv2.putText(img,text,tl,cv2.FONT_HERSHEY_PLAIN,2,txt_color,3)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "plt.subplots_adjust(left=0.2, wspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single example excution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "img = cv2.imread(os.path.join('custom_darkflow','test_images','6.jpg'))\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "result = tfnet.return_predict(img)\n",
    "for r in result:\n",
    "    tl = (r['topleft']['x'], r['topleft']['y'])\n",
    "    br = (r['bottomright']['x'], r['bottomright']['y'])\n",
    "    label = r['label']\n",
    "    if label == 'dog':     \n",
    "#             conf = r['confidence'] # confidence of general dog detector\n",
    "#             text = '{}({:.2f})'.format(label,conf)\n",
    "        predict_class,predict_rate = HappyPrediction(img) # confidence of happy dog classifier\n",
    "        text = '{}({:.2f})'.format(predict_class,predict_rate)\n",
    "        (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN,2,5)[0]\n",
    "        text_offset_x = tl[0]-3\n",
    "        text_offset_y = tl[1]\n",
    "        box_coords = ((text_offset_x, text_offset_y+10), (text_offset_x+text_width,text_offset_y-text_height-10))\n",
    "        if predict_class == 'happy':\n",
    "            box_color = happy_box_color\n",
    "        else:\n",
    "            box_color = sad_box_color\n",
    "        img = cv2.rectangle(img, box_coords[0], box_coords[1], box_color, cv2.FILLED)\n",
    "        img = cv2.rectangle(img,tl,br,box_color,thickness=4)\n",
    "        img = cv2.putText(img,text,tl,cv2.FONT_HERSHEY_PLAIN,2,txt_color,3)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.subplots_adjust(left=0.2, wspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for video input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only showing happy dogs ##\n",
    "url = 'https://www.youtube.com/watch?v=0lEUiQEDUHM'\n",
    "pa = pafy.new(url)\n",
    "play = pa.getbest(preftype='webm')\n",
    "cap = cv2.VideoCapture(play.url)\n",
    "\n",
    "if (cap.isOpened() == False):\n",
    "    print('cannot read a video')\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('HDD_testing.avi',fourcc,20.0,(640,360))\n",
    "\n",
    "while cap.isOpened():\n",
    "    stime = time.time()\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        frame = np.asarray(frame)\n",
    "        result = tfnet.return_predict(frame)\n",
    "        new_frame = np.copy(frame)\n",
    "        for r in result:\n",
    "            tl = (r['topleft']['x'], r['topleft']['y'])\n",
    "            br = (r['bottomright']['x'], r['bottomright']['y'])\n",
    "            label = r['label']\n",
    "            if label == 'dog':\n",
    "                predict_class,predict_rate = HappyPrediction(new_frame) # confidence of happy dog classifier\n",
    "                if predict_class == 'happy':       \n",
    "                    text = '{}({:.2f})'.format(predict_class,predict_rate)\n",
    "                    box_color = happy_box_color\n",
    "                    (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN,2,5)[0]\n",
    "                    text_offset_x = tl[0]-3\n",
    "                    text_offset_y = tl[1]\n",
    "                    box_coords = ((text_offset_x, text_offset_y+10), (text_offset_x+text_width,text_offset_y-text_height-10))\n",
    "                    new_frame = cv2.rectangle(new_frame, box_coords[0], box_coords[1], box_color, cv2.FILLED)\n",
    "                    new_frame = cv2.rectangle(new_frame,tl,br,box_color,thickness=4)\n",
    "                    new_frame = cv2.putText(new_frame,text,tl,cv2.FONT_HERSHEY_PLAIN,2,txt_color,3)\n",
    "        fps = 1/(time.time()-stime)\n",
    "        new_frame = cv2.putText(new_frame,'fps: '+format(fps, '.2f'),(0,15),cv2.FONT_HERSHEY_PLAIN,1,(0,0,0),2)\n",
    "        out.write(new_frame)\n",
    "        cv2.imshow('frame',new_frame)\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/watch?v=0lEUiQEDUHM'\n",
    "pa = pafy.new(url)\n",
    "play = pa.getbest(preftype='webm')\n",
    "cap = cv2.VideoCapture(play.url)\n",
    "\n",
    "if (cap.isOpened() == False):\n",
    "    print('cannot read a video')\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('HDD_testing.avi',fourcc,20.0,(640,360))\n",
    "\n",
    "while cap.isOpened():\n",
    "    stime = time.time()\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        frame = np.asarray(frame)\n",
    "        result = tfnet.return_predict(frame)\n",
    "        new_frame = np.copy(frame)\n",
    "        for r in result:\n",
    "            tl = (r['topleft']['x'], r['topleft']['y'])\n",
    "            br = (r['bottomright']['x'], r['bottomright']['y'])\n",
    "            label = r['label']\n",
    "            if label == 'dog':\n",
    "                predict_class,predict_rate = HappyPrediction(new_frame) # confidence of happy dog classifier\n",
    "                if predict_class == 'happy':       \n",
    "                    text = '{}({:.2f})'.format(predict_class,predict_rate)\n",
    "                    box_color = happy_box_color\n",
    "                else:\n",
    "                    text = '{}'.format(predict_class)\n",
    "                    box_color = sad_box_color\n",
    "                (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN,2,5)[0]\n",
    "                text_offset_x = tl[0]-3\n",
    "                text_offset_y = tl[1]\n",
    "                box_coords = ((text_offset_x, text_offset_y+10), (text_offset_x+text_width,text_offset_y-text_height-10))\n",
    "#                 if predict_class == 'happy':\n",
    "#                     box_color = happy_box_color\n",
    "#                 else:\n",
    "#                     box_color = sad_box_color\n",
    "                new_frame = cv2.rectangle(new_frame, box_coords[0], box_coords[1], box_color, cv2.FILLED)\n",
    "                new_frame = cv2.rectangle(new_frame,tl,br,box_color,thickness=4)\n",
    "                new_frame = cv2.putText(new_frame,text,tl,cv2.FONT_HERSHEY_PLAIN,2,txt_color,3)\n",
    "        fps = 1/(time.time()-stime)\n",
    "        new_frame = cv2.putText(new_frame,'fps: '+format(fps, '.2f'),(0,15),cv2.FONT_HERSHEY_PLAIN,1,(0,0,0),2)\n",
    "        out.write(new_frame)\n",
    "        cv2.imshow('frame',new_frame)\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for webcam input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = (tuple(255*np.random.rand(3) for _ in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture = cv2.VideoCapture(0)\n",
    "# capture.set(cv2.CAP_PROP_FRAME_WIDTH,1920)\n",
    "# capture.set(cv2.CAP_PROP_FRAME_HEIGHT,1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     stime = time.time()\n",
    "#     ret,frame = capture.read()\n",
    "    \n",
    "#     if ret:\n",
    "#         results = tfnet.return_predict(frame)\n",
    "#         for color,r in zip(colors,results):\n",
    "#             tl = (r['topleft']['x'], r['topleft']['y'])\n",
    "#             br = (r['bottomright']['x'], r['bottomright']['y'])\n",
    "#             label = r['label']\n",
    "#             frame = cv2.rectangle(frame,tl,br,color,5)\n",
    "#             frame = cv2.putText(frame,label,tl,cv2.FONT_HERSHEY_PLAIN,2,color,3)\n",
    "#         cv2.imshow('frame',frame)\n",
    "#         print('FPS {:.1f}'.format(1/(time.time()-stime)))\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# capture.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-gpu",
   "language": "python",
   "name": "cv-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
